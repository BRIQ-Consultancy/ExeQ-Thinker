-----

````markdown
<p align="center">
  <img src="https://github.com/user-attachments/assets/50fe082c-141a-42a5-92d0-089bad5a0e1b" alt="BRIQ Logo" width="150"/>
</p>

<h1 align="center">âš¡ï¸ ExeQ Thinker</h1>

<p align="center">
  <strong><i>â€œBÄ±rakÄ±n, gÃ¶rÃ¼nmeyen desenler gerÃ§eÄŸi ortaya Ã§Ä±karsÄ±n.â€</i></strong>
  <br />
  <br />
  KarmaÅŸÄ±k analiz, stratejik planlama ve gÃ¼venilir sonuÃ§lar iÃ§in tasarlanmÄ±ÅŸ, derinlemesine dÃ¼ÅŸÃ¼nen bir biliÅŸsel mimari.
</p>

<p align="center">
    <a href="#"><img src="https://img.shields.io/badge/Python-3.11+-blue?logo=python&logoColor=white" alt="Python Version"></a>
    <a href="#"><img src="https://img.shields.io/badge/License-MIT-green.svg" alt="License"></a>
    <a href="#"><img src="https://img.shields.io/badge/Status-Aktif-brightgreen" alt="Project Status"></a>
    <a href="#"><img src="https://img.shields.io/github/stars/your-org/exeq-thinker?style=social" alt="GitHub Stars"></a>
</p>

---

## ğŸ¯ Neden ExeQ Thinker?

Standart Dil Modelleri (LLM), tek adÄ±mlÄ±k gÃ¶revlerde harikalar yaratÄ±r ancak karmaÅŸÄ±k, Ã§ok aÅŸamalÄ± ve belirsiz problemler karÅŸÄ±sÄ±nda yetersiz kalÄ±r. CevaplarÄ± yÃ¼zeysel olabilir, kritik detaylarÄ± gÃ¶zden kaÃ§Ä±rabilir ve tutarsÄ±z sonuÃ§lar Ã¼retebilirler.

**ExeQ Thinker** ise bu sorunu Ã§Ã¶zmek iÃ§in geliÅŸtirilmiÅŸ bir **biliÅŸsel mimaridir (cognitive architecture)**. Basit bir "soru-cevap" mekanizmasÄ± yerine, problemi alt gÃ¶revlere ayÄ±ran, her adÄ±mÄ± eleÅŸtirel bir sÃ¼zgeÃ§ten geÃ§iren ve araÃ§larÄ± (tool) akÄ±llÄ±ca kullanarak en doÄŸru sonuca ulaÅŸan **planlayÄ±cÄ±-eleÅŸtirmen (planner-critic)** dÃ¶ngÃ¼lerini kullanÄ±r.

Bu yapÄ±, onu aÅŸaÄŸÄ±dakiler iÃ§in vazgeÃ§ilmez kÄ±lar:
- ğŸ§  **AraÅŸtÄ±rmacÄ±lar:** KanÄ±ta dayalÄ±, denetlenebilir ve tekrarlanabilir analiz zincirleri oluÅŸturmak iÃ§in.
- âš™ï¸ **MÃ¼hendisler:** GÃ¼venilir araÃ§ kullanÄ±mÄ± (tool-use), yapÄ±landÄ±rÄ±lmÄ±ÅŸ veri (JSON) Ã§Ä±ktÄ±sÄ± ve otomasyon sÃ¼reÃ§leri iÃ§in.
- ğŸ¢ **Kurumlar:** Ãœretim ortamÄ±na hazÄ±r, denetim kayÄ±tlarÄ± (audit logs) tutan ve Ã¶ngÃ¶rÃ¼lebilir yapay zeka kararlarÄ± iÃ§in.

---

## âœ¨ Temel Ã–zellikler

- ğŸ§­ **Derinlemesine ve Ã‡ok AdÄ±mlÄ± AkÄ±l YÃ¼rÃ¼tme:** Bir problemi atomik parÃ§alarÄ±na ayÄ±rÄ±r, her birini analiz eder ve sonuÃ§larÄ± sentezleyerek yÃ¼ksek gÃ¼venilirlikli Ã§Ä±ktÄ±lar Ã¼retir. Bu, "Chain of Thought" mekanizmasÄ±nÄ±n Ã§ok daha geliÅŸmiÅŸ bir versiyonudur.

- ğŸš€ **Optimize EdilmiÅŸ Performans:** **Flash Attention 2** gibi en son GPU optimizasyonlarÄ± sayesinde, dikkat mekanizmasÄ±nÄ±n karesel ($O(N^2)$) karmaÅŸÄ±klÄ±ÄŸÄ±nÄ± Ã§izgisel ($O(N)$) seviyesine indirir. Bu, daha az VRAM kullanÄ±mÄ± ve Ã§ok daha yÃ¼ksek Ã§Ä±karÄ±m (inference) hÄ±zlarÄ± anlamÄ±na gelir.

- ğŸ› ï¸ **GeniÅŸletilebilir AraÃ§ (Tool) Ekosistemi:** RAG (Retrieval-Augmented Generation) pipeline'larÄ±, harici API'lar, veritabanlarÄ± veya Ã¶zel veri kaynaklarÄ± gibi herhangi bir aracÄ± sisteme kolayca entegre edin.

- ğŸ”’ **Ãœretim OrtamÄ±na HazÄ±r (Production-Ready):**
  - **Token BÃ¼tÃ§eleme:** Sonsuz dÃ¶ngÃ¼leri ve beklenmedik maliyetleri Ã¶nlemek iÃ§in her iÅŸlemde token kullanÄ±mÄ±nÄ± akÄ±llÄ±ca yÃ¶netir.
  - **Durum YÃ¶netimi (Stateful Memory):** KonuÅŸma geÃ§miÅŸini ve ara adÄ±mlarÄ± yÃ¶neterek baÄŸlamÄ± asla kaybetmez.
  - **GÃ¼venlik KorkuluklarÄ± (Guardrails):** Ä°stenmeyen veya zararlÄ± iÃ§erik Ã¼retimini engeller ve sistemin gÃ¼venilirliÄŸini artÄ±rÄ±r.
  - **DetaylÄ± Loglama:** Her bir dÃ¼ÅŸÃ¼nce adÄ±mÄ±nÄ±, araÃ§ Ã§aÄŸrÄ±sÄ±nÄ± ve kararÄ±nÄ± kaydederek tam bir denetlenebilirlik saÄŸlar.

- ğŸ§  **Ã–zel Olarak Ä°nce AyarlanmÄ±ÅŸ Model (`gpt-oss:20b-exeq`):**
  - **Temel Model:** GÃ¼Ã§lÃ¼ ve aÃ§Ä±k kaynaklÄ± `ollama gpt-oss:20b`.
  - **EÄŸitim Verisi:** AkÄ±l yÃ¼rÃ¼tme, planlama ve araÃ§ kullanÄ±mÄ± Ã¼zerine odaklanmÄ±ÅŸ, **1.8 milyon ham Ã¶rnekten oluÅŸan (toplamda 400 milyar token'dan fazla)** devasa bir veri seti ile ince ayar (fine-tuning) yapÄ±lmÄ±ÅŸtÄ±r. Bu, modelin karmaÅŸÄ±k talimatlarÄ± anlama ve uygulama yeteneÄŸini zirveye taÅŸÄ±r.

---

## ğŸ—ï¸ Mimari: ExeQ NasÄ±l DÃ¼ÅŸÃ¼nÃ¼r?

ExeQ Thinker, insan beyninin bir problemi Ã§Ã¶zerken izlediÄŸi "dÃ¼ÅŸÃ¼n-eleÅŸtir-eyleme geÃ§" dÃ¶ngÃ¼sÃ¼nÃ¼ taklit eder. SÃ¼reÃ§, aÅŸaÄŸÄ±daki adÄ±mlarla iÅŸler:

```mermaid
graph TD
    subgraph "KullanÄ±cÄ± EtkileÅŸimi"
        A[ğŸ‘¤ KullanÄ±cÄ± Sorusu]
    end

    subgraph "ExeQ Thinker Ã‡ekirdeÄŸi"
        B[ğŸ§  OrkestratÃ¶r]
        C[ğŸ“ PlanlayÄ±cÄ±]
        D[ğŸ” EleÅŸtirmen/Sentezleyici]
        E[ğŸ› ï¸ AraÃ§ YÃ¶nlendirici]
        F[ğŸ’¾ Bellek YÃ¶neticisi]
    end

    subgraph "Hesaplama ve Veri KatmanÄ±"
        G[ğŸš€ GPU ile HÄ±zlandÄ±rÄ±lmÄ±ÅŸ Model (gpt-oss:20b-exeq)]
        H[ğŸ“š Harici AraÃ§lar (RAG, API'ler, DB)]
    end

    subgraph "Ã‡Ä±ktÄ±"
        I[ğŸ’¬ AnlÄ±k AkÄ±ÅŸ (Streaming) Cevap]
    end

    A --> B
    B -- Problem Analizi --> C
    C -- AdÄ±m AdÄ±m Plan OluÅŸturur --> B
    B -- GÃ¶revi YÃ¶nlendirir --> E
    E -- Gerekli AracÄ± Ã‡aÄŸÄ±rÄ±r --> H
    H -- SonuÃ§larÄ± DÃ¶ndÃ¼rÃ¼r --> D
    C -- PlanÄ± GÃ¶nderir --> D
    F -- BaÄŸlam ve GeÃ§miÅŸi SaÄŸlar --> D
    D -- SonuÃ§larÄ± ve PlanÄ± DeÄŸerlendirir, Gerekirse Revize iÃ§in PlanlayÄ±cÄ±ya Geri GÃ¶nderir --> B
    B -- Nihai Cevap iÃ§in SentezlenmiÅŸ Veriyi GÃ¶nderir --> I
    
    C -- Model Ã‡aÄŸrÄ±sÄ± --> G
    D -- Model Ã‡aÄŸrÄ±sÄ± --> G
    E -- Model Ã‡aÄŸrÄ±sÄ± --> G

    style B fill:#1E90FF,stroke:#333,stroke-width:2px,color:#fff
    style G fill:#FF4500,stroke:#333,stroke-width:2px,color:#fff
````

1.  **Orkestrasyon:** KullanÄ±cÄ±dan gelen karmaÅŸÄ±k talep, ilk olarak **OrkestratÃ¶r** tarafÄ±ndan alÄ±nÄ±r.
2.  **Planlama:** **PlanlayÄ±cÄ±**, bu talebi Ã§Ã¶zmek iÃ§in gereken mantÄ±ksal adÄ±mlarÄ± (Ã¶rneÄŸin, "Ã–nce veriyi topla", "Sonra veriyi analiz et", "En son raporu hazÄ±rla") oluÅŸturur.
3.  **AraÃ§ KullanÄ±mÄ±:** Her adÄ±m iÃ§in gerekli olan araÃ§ (bir RAG sorgusu, bir API Ã§aÄŸrÄ±sÄ± vb.) **AraÃ§ YÃ¶nlendirici** tarafÄ±ndan yÃ¼rÃ¼tÃ¼lÃ¼r.
4.  **EleÅŸtiri ve Sentez:** **EleÅŸtirmen**, aracÄ±n dÃ¶ndÃ¼rdÃ¼ÄŸÃ¼ sonuÃ§larÄ± ve planÄ±n ilerleyiÅŸini deÄŸerlendirir. "Bu sonuÃ§ yeterli mi?", "PlanÄ± deÄŸiÅŸtirmem gerekiyor mu?" gibi sorular sorar.
5.  **DÃ¶ngÃ¼:** EÄŸer sonuÃ§ yetersizse, dÃ¶ngÃ¼ planlama veya araÃ§ kullanma adÄ±mÄ±na geri dÃ¶ner. Yeterliyse, bir sonraki adÄ±ma geÃ§ilir.
6.  **Bellek:** TÃ¼m bu sÃ¼reÃ§ boyunca **Bellek YÃ¶neticisi**, geÃ§miÅŸ adÄ±mlarÄ±, sonuÃ§larÄ± ve token bÃ¼tÃ§esini yÃ¶netir.
7.  **Cevap AkÄ±ÅŸÄ±:** SonuÃ§lar kesinleÅŸtikÃ§e, kullanÄ±cÄ±ya **anlÄ±k akÄ±ÅŸ (streaming)** olarak gÃ¶nderilir. Bu sayede kullanÄ±cÄ±, dÃ¼ÅŸÃ¼nme sÃ¼recini canlÄ± olarak takip edebilir.

-----

## ğŸ“Š Performans KarÅŸÄ±laÅŸtÄ±rmasÄ±

Bu alanda ExeQ Thinker'Ä±n, diÄŸer yerel (local) Ollama modellerine kÄ±yasla karmaÅŸÄ±k gÃ¶revlerdeki performansÄ±nÄ± gÃ¶steren bir grafik yer alacaktÄ±r.

-----

-----

-----

-----

## ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§

### 1\. Projeyi KlonlayÄ±n

```bash
git clone [https://github.com/your-org/exeq-thinker.git](https://github.com/your-org/exeq-thinker.git)
cd exeq-thinker
```

### 2\. OrtamÄ± OluÅŸturun ve Aktif Edin

```bash
conda create -n exeq-turbo python=3.11 -y
conda activate exeq-turbo
```

### 3\. BaÄŸÄ±mlÄ±lÄ±klarÄ± YÃ¼kleyin

```bash
pip install -r requirements.txt
```

### 4\. Sunucuyu BaÅŸlatÄ±n

```bash
python app.py
```

ArtÄ±k ExeQ Thinker `http://localhost:5001` adresinde Ã§alÄ±ÅŸÄ±yor\!

-----

## ğŸ’» KullanÄ±m Ã–rneÄŸi

AÅŸaÄŸÄ±daki `cURL` komutu ile sisteme karmaÅŸÄ±k bir bilimsel soru sorarak dÃ¼ÅŸÃ¼nme yeteneÄŸini test edebilirsiniz:

```bash
curl -X POST http://localhost:5001/chat \
     -H "Content-Type: application/json" \
     -d '{
       "message": "Einsteinâ€™Ä±n genel gÃ¶relilik teorisi ile Stephen Hawkingâ€™in kara delikler Ã¼zerine yaptÄ±ÄŸÄ± Ã§alÄ±ÅŸmalar arasÄ±nda, hangi noktada ve neden uzlaÅŸmaz bir fark ortaya Ã§Ä±kmaktadÄ±r?"
     }'
```

-----

## ğŸ“‚ Proje YapÄ±sÄ±

\<details\>
\<summary\>Dizin yapÄ±sÄ±nÄ± gÃ¶rmek iÃ§in tÄ±klayÄ±n\</summary\>

```
exeq-turbo/
â”‚
â”œâ”€â”€ app.py                # FastAPI sunucusu ve API endpoint'leri
â”œâ”€â”€ requirements.txt      # Gerekli Python kÃ¼tÃ¼phaneleri
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ core/             # OrkestratÃ¶r, planlayÄ±cÄ± ve eleÅŸtirmen mantÄ±ÄŸÄ±
â”‚   â”œâ”€â”€ memory/           # KonuÅŸma geÃ§miÅŸi ve token bÃ¼tÃ§eleme modÃ¼lleri
â”‚   â”œâ”€â”€ tools/            # RAG ve harici araÃ§ yÃ¶nlendiricisi
â”‚   â””â”€â”€ models/           # LLM entegrasyonlarÄ± ve Ã§Ä±karÄ±m optimizasyonlarÄ±
â”‚
â”œâ”€â”€ tests/                # Birim ve entegrasyon testleri
â”‚
â””â”€â”€ docs/                 # DetaylÄ± dokÃ¼mantasyon
```

\</details\>

-----

## ğŸ¤ KatkÄ±da Bulunma

KatkÄ±larÄ±nÄ±zÄ± bekliyoruz\! LÃ¼tfen `CONTRIBUTING.md` dosyasÄ±nÄ± inceleyerek pull request aÃ§Ä±n veya yeni bir issue oluÅŸturun.

## ğŸ“„ Lisans

Bu proje MIT LisansÄ± altÄ±nda lisanslanmÄ±ÅŸtÄ±r. Detaylar iÃ§in `LICENSE` dosyasÄ±na gÃ¶z atÄ±n.

```
```
